{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Gender from Personality Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes through the process of building various simple models to predict gender from the answers on personality questions.  There is a lot of exploration in this notebook--much more so than necessary--to show the variation in performance between the different model types.  The general methodology for this process will be to fit multiple \"standard\" models (of the same model type) and select the best one for parameter tuning and optimization.  This methodology isn't exactly *ideal*, because it is very possible for one of the non-selected models to have the best performance after tuning--but it works *good enough* in most situations.  In a situation where there's a huge cost to misclassification then it would be more appropriate to get into the more extreme edges of model tuning--but this ain't it.\n",
    "\n",
    "In the next notebook, information discovered here will be used with other techniques to build a single good model that predicts gender from personality questions.\n",
    "\n",
    "**Note:** In this exploration, I did not split use a hold-away test set to evaluate the best hyperparameters after tuning.  For this notebook, I was mainly looking to get a feel for which models to use in an ensemble and get a rough estimate of potential max accuracy.  I'm well aware that you cannot use crossvalidation to tune hyperparameters and have the crossvalidation accuracy be a reliable indicator of the actual accuracy of the model.  Said crossval accuracy will, however, give me an approximate upperbound I can expect out of each model because I don't, in general, expect performance to be better on a held-away test set than on the data the hyperparameters were tuned on.  In the next notebook planned (where I actually build the ensemble model), a proper train/test split will be used with *nothing* being done to the models on the test set outside of evaluating accuracy.\n",
    "\n",
    "If you have feedback (positive or negative) for me, I'd love to hear it and would be forever grateful.  Even on the presentation itself--I definitely know my aesthetics definitely need work.  I know that various cells were run out of order but I promise that the entire notebook works from start to finish with no issues.  Running them out-of-order was a workaround for needing to close my laptop to transport it and Jupyter Notebooks not currently allowing output to save to the notebook without notebook open in a browser.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [Load Data and Libraries](#load_data)\n",
    "- [Data Preparation](#data_prep)\n",
    "- [Logarithmic Regression Models](#log_reg)\n",
    "- [Naive-Bayes Models](#nb)\n",
    "- [Support Vector Machine Models](#svm)\n",
    "- [K-Nearest Neighbors Models](#knn)\n",
    "- [Ensemble Decision Tree Models](#trees)\n",
    "- [Conclusions](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load_data\"></a>\n",
    "## Load Data and Install Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>sqrtbox_age</th>\n",
       "      <th>box_accuracy</th>\n",
       "      <th>box_elapsed</th>\n",
       "      <th>bin_age</th>\n",
       "      <th>bin_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>US</td>\n",
       "      <td>5</td>\n",
       "      <td>914</td>\n",
       "      <td>1.683215</td>\n",
       "      <td>2.270186</td>\n",
       "      <td>9.774004</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>891</td>\n",
       "      <td>1.900242</td>\n",
       "      <td>2.287068</td>\n",
       "      <td>9.723672</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>US</td>\n",
       "      <td>5</td>\n",
       "      <td>903</td>\n",
       "      <td>1.853102</td>\n",
       "      <td>2.240760</td>\n",
       "      <td>9.750076</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>806</td>\n",
       "      <td>1.861649</td>\n",
       "      <td>2.272403</td>\n",
       "      <td>9.526909</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>NZ</td>\n",
       "      <td>0</td>\n",
       "      <td>1826</td>\n",
       "      <td>1.956691</td>\n",
       "      <td>2.258593</td>\n",
       "      <td>11.190933</td>\n",
       "      <td>4</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1  A2  A3  A4  A5  A6  A7  A8  A9  A10     ...       gender  accuracy  \\\n",
       "0   1   4   2   3   3   2   3   4   4    3     ...            1        92   \n",
       "1   4   3   4   3   4   4   4   4   2    2     ...            1       100   \n",
       "2   3   4   4   4   4   4   4   3   2    2     ...            1        80   \n",
       "3   4   5   4   4   4   3   3   2   2    2     ...            1        93   \n",
       "4   4   0   4   4   4   3   5   1   2    4     ...            2        87   \n",
       "\n",
       "   country  source  elapsed  sqrtbox_age  box_accuracy  box_elapsed  bin_age  \\\n",
       "0       US       5      914     1.683215      2.270186     9.774004        0   \n",
       "1       US       0      891     1.900242      2.287068     9.723672        4   \n",
       "2       US       5      903     1.853102      2.240760     9.750076        3   \n",
       "3       US       0      806     1.861649      2.272403     9.526909        3   \n",
       "4       NZ       0     1826     1.956691      2.258593    11.190933        4   \n",
       "\n",
       "   bin_country  \n",
       "0           US  \n",
       "1           US  \n",
       "2           US  \n",
       "3           US  \n",
       "4        Other  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data_trans.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_prep\"></a>\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Invalid Data\n",
    "\n",
    "As we removed all rows that had invalid data in the feature (personality questions) columns in the EDA phase, we only need to remove invalid data in the target variable (gender).  From the variable descriptions, any gender represented by 0 means that no answer was provided so they'll be absolutely no help to us (obvi).  It should be noted that the features all exist on the same scale and thus don't need to be scaled or normalized to avoid one feature overpowering other features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows of data: 48779\n",
      "\n",
      "Number of rows remaining after deleting 'no answer' genders: 48543\n",
      "\n",
      "Total number of rows removed: 236\n",
      "\n",
      "Value counts for gender: \n",
      "2    29046\n",
      "1    19227\n",
      "3      270\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "Women as a pct of total data: 0.5983560966565725\n",
      "\n",
      "Men as a pct of total data: 0.3960818243619059\n",
      "\n",
      "Non-binary as a pct of total data: 0.0055620789815215375\n"
     ]
    }
   ],
   "source": [
    "df.gender.value_counts(dropna=False)\n",
    "og_count = df.shape[0]\n",
    "print('\\nTotal rows of data: '+str(og_count))\n",
    "df = df[df.gender!=0]\n",
    "new_count = df.shape[0]\n",
    "print(\"\\nNumber of rows remaining after deleting 'no answer' genders: \"+str(new_count))\n",
    "print(\"\\nTotal number of rows removed: \"+str(og_count-new_count))\n",
    "print(\"\\nValue counts for gender: \")\n",
    "values = df.gender.value_counts()\n",
    "print(values)\n",
    "print(\"\\nWomen as a pct of total data: \"+str(values[2]/new_count))\n",
    "print(\"\\nMen as a pct of total data: \"+str(values[1]/new_count))\n",
    "print(\"\\nNon-binary as a pct of total data: \"+str(values[3]/new_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the EDA, this data is pretty imbalanced with a lot of data on women (about 60% of the total) and very, very, very few non-binary genders (about 0.5% total).  This will really limit the ability of our models to predict non-binary gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models will be evaluated using stratified k-fold crossvalidation.  We will drop binary gender for now and treat this as a binary classification problem.  Later on we will work to expand the results and see if we can make useful predictions for whether someone is non-binary or not, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rando_seed = 17\n",
    "\n",
    "non_features = ['age', 'accuracy', 'elapsed', 'gender', 'source', 'country',\n",
    "               'sqrtbox_age', 'box_accuracy', 'box_elapsed', 'bin_age', 'bin_country']\n",
    "\n",
    "# create a copy dataset but drop all non-binary genders (which makes it a binary classification problem)\n",
    "# re-code binary variables to be 0/1 instead of 1/2\n",
    "X = df.drop(non_features, axis=1)\n",
    "y = df.gender\n",
    "X = X[y>0]\n",
    "y = y[y>0]\n",
    "X_bi = X[y<3]\n",
    "y_bi = y[y<3]\n",
    "y_bi = y_bi-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of binary target variable: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    29046\n",
       "0    19227\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Distribution of binary target variable: ')\n",
    "y_bi.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points: 48273\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of data points: {str(len(X_bi))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heavily Used Functions for this Notebook\n",
    "Below are a couple function I'm going to use to make this analysis more streamlined and effective.  Instead of using sklearn's cross_val_score function to estimate crossvalidation accuracy, I'll be using a custom function which does the same thing but will allow me to include multiple metrics as well as return the accuracy scores for the training data for each fold (as opposed to just the test accuracy for each fold).  Getting the training accuracy of the models as well as the test accuracy will allow me to get an indication of whether overfitting is inherent in the model being fit or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#sklearn kind of sucks and puts out a lot of metric warnings--especially when you have an extreme minority class that may\n",
    "#not get predicted.\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "rando_seed = 17\n",
    "\n",
    "bold = \"\\033[1m\"\n",
    "reset = \"\\033[0;0m\"\n",
    "\n",
    "def bold_print(string):\n",
    "    print(bold+string+reset)\n",
    "\n",
    "def train_and_report(model, n_folds=5, X=X_bi, y=y_bi):\n",
    "    t0 = time.time()\n",
    "    test_metrics = strat_kfold(model, X, y, num_folds=n_folds, random_state=rando_seed)\n",
    "    t1 = time.time()\n",
    "    print(\"\\nAverage crossval scores for best model: \")\n",
    "    print(model_eval(test_metrics))\n",
    "    timed = round((t1-t0)/n_folds, 2)\n",
    "    print(f\"\\nTime to train model on each fold was {timed} seconds average.\")\n",
    "\n",
    "def metric_report(x_vals, y_vals, model, auc=False):\n",
    "    '''\n",
    "    Prints a quick snapshot of the accuracy of a model on a particular dataset.\n",
    "    \n",
    "    param x_vals:  The model input variables\n",
    "    param y_vals:  The model label variable\n",
    "    param model:   The model itself\n",
    "    param auc:     If true, calculate area under ROC\n",
    "    '''\n",
    "    y_pred = model.predict(x_vals)\n",
    "    print(\"Accuracy score: \"+str(accuracy_score(y_vals, y_pred)))\n",
    "    print(\"\\nClassification report: \")\n",
    "    print(classification_report(y_vals, y_pred))\n",
    "    if auc:\n",
    "        print(\"Area under ROC: \"+str(roc_auc_score(y_vals, y_pred)))\n",
    "\n",
    "def strat_kfold(model, x_vals, y_vals, num_folds=5, metrics=None, random_state=None, \n",
    "                df_columns=None, train_metrics=False, fit_kwargs={}, predict_kwargs={},\n",
    "                verbose=False):\n",
    "    '''\n",
    "    Custom stratified k-fold function.  Functions the same as most stratified k-fold methods but will\n",
    "        return a list of metrics instead of just the one that sklearn returns.\n",
    "    \n",
    "    param model:        The model itself\n",
    "    param x_vals:       The model input variables\n",
    "    param y_vals:       The model label variable\n",
    "    param num_folds:    Number of folds to use\n",
    "    param metrics:      A list of functions used to calculate whatever metrics you want.  Function\n",
    "                            must take only X and y values and return a number.  If None, defaults to\n",
    "                            accuracy and F1 score\n",
    "    param random_state: Random seed\n",
    "    param df_columns:   The names of the custom metrics used.  If no df_column given, entire function returns\n",
    "                            a numpy array.  If column names are given, returns a pandas DataFrame.\n",
    "    param train_metrics:If True, returns the accuracy metrics for the training set and the testing set for each fold.\n",
    "                            If False, returns just the accuracy of the testing set for each fold.\n",
    "    param verbose:      If True, prints a progress bar that counts each fold.\n",
    "    \n",
    "    Returns:            Either a numpy array or dataframe with dimensions - (number of folds, number of metrics)\n",
    "                            Each column represents a model metric and each row represents a given fold.  If\n",
    "                            train_metrics=True, returns two such array/DFs: one for the training set of each fold and\n",
    "                            one for the testing set of each fold.\n",
    "    '''\n",
    "    folds = StratifiedKFold(num_folds, random_state=random_state)\n",
    "    if not metrics:\n",
    "        if not df_columns:\n",
    "            df_columns = ['Accuracy', 'F1']\n",
    "        metrics=[accuracy_score, f1_score]\n",
    "    num_metrics = len(metrics)\n",
    "    metric_grid_train = np.zeros((num_folds, num_metrics))\n",
    "    metric_grid_test = np.zeros((num_folds, num_metrics))\n",
    "    current_fold = 0\n",
    "    for train, test in tqdm_notebook(folds.split(x_vals, y_vals), disable=(not verbose)):\n",
    "        x_train, x_test = x_vals.iloc[train], x_vals.iloc[test]\n",
    "        y_train, y_test = y_vals.iloc[train], y_vals.iloc[test]\n",
    "        clf = model.fit(x_train, y_train)\n",
    "        y_train_pred = clf.predict(x_train)\n",
    "        y_test_pred = clf.predict(x_test)\n",
    "        for metric_index in range(num_metrics):\n",
    "            metric=metrics[metric_index]\n",
    "            metric_grid_train[current_fold][metric_index] = metric(y_train, y_train_pred)\n",
    "            metric_grid_test[current_fold][metric_index] = metric(y_test, y_test_pred)\n",
    "        current_fold+=1\n",
    "    if df_columns:\n",
    "        metric_grid_train = pd.DataFrame(metric_grid_train, columns=df_columns)\n",
    "        metric_grid_test = pd.DataFrame(metric_grid_test, columns=df_columns)           \n",
    "    if train_metrics:\n",
    "        return metric_grid_train, metric_grid_test\n",
    "    else:\n",
    "        return metric_grid_test\n",
    "\n",
    "def avg_kfold_metrics(metric_grid, return_tuple=False):\n",
    "    '''\n",
    "    Quick function to average columns and give an overall estimate for the k-fold grid output of strat_kfold\n",
    "    \n",
    "    Takes a metric_grid output from the strat_kfold function and calculates the average for each metric for each fold\n",
    "    '''\n",
    "    if return_tuple:\n",
    "        return tuple(np.mean(metric_grid, axis=0))\n",
    "    else:\n",
    "        return np.mean(metric_grid, axis=0)\n",
    "\n",
    "def std_kfold_metrics(metric_grid, return_tuple=False):\n",
    "    '''\n",
    "    Quick function to calculate standard deviation of columns and give an overall \n",
    "    estimate for the k-fold grid output of strat_kfold\n",
    "    \n",
    "    Takes a metric_grid output from the strat_kfold function and calculates the standard deviation for each metric for each fold\n",
    "    '''\n",
    "    if return_tuple:\n",
    "        return tuple(np.std(metric_grid, axis=0))\n",
    "    else:\n",
    "        return np.std(metric_grid, axis=0)\n",
    "\n",
    "def model_eval(metric_grid, name=None):\n",
    "    '''\n",
    "    Quick function to combine the avg- and std-kfold metric functions and make it look pretty\n",
    "    '''\n",
    "    if name:\n",
    "        col_names = [name+\" AVG\", name+\" STD\"]\n",
    "    else:\n",
    "        col_names = [\"AVG\", \"STD\"]\n",
    "    avg_c = avg_kfold_metrics(metric_grid)\n",
    "    std_c = std_kfold_metrics(metric_grid)\n",
    "    new = pd.concat([avg_c.rename(col_names[0]), std_c.rename(col_names[1])], axis=1)\n",
    "    return new\n",
    "\n",
    "def train_test_eval(train_grid, test_grid, name=None):\n",
    "    '''\n",
    "    Quick function to print a super pretty model_eval for train and test kfold grids together\n",
    "    '''\n",
    "    bold_print(\"\\n\\nTraining crossvalidation metrics average: \")\n",
    "    print(model_eval(train_metrics))\n",
    "    bold_print(\"\\n\\nTesting crossvalidation metrics average: \")\n",
    "    print(model_eval(test_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DAB!](https://purepng.com/public/uploads/thumbnail/purepng.com-fortnite-dabfortnitefortnite-battle-royalebattle-royaleepic-gamesgames-1251525434679cpsea.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"log_reg\"></a>\n",
    "## Logistic Regression\n",
    "\n",
    "The first few models built will be logistic regression models.  Logistic regression is one of my favorite methods for binary classification--it's quick and easy, there aren't too many hyperparameters to tune and it usually gives \"good enough\" results.  Another positive is that the predicted probabilities are usually well-calibrated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Default Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.803622  0.001489\n",
      "F1        0.840781  0.001140\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.801628  0.006167\n",
      "F1        0.839175  0.005369\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=rando_seed)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_bi, y_bi, train_metrics=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with a cost function weighted by counts of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.797558  0.001528\n",
      "F1        0.825820  0.001379\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.794813  0.006572\n",
      "F1        0.823369  0.006579\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(class_weight='balanced', random_state=rando_seed)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_bi, y_bi, train_metrics=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will tune the C parameter and the weighting scheme of the logistic regression model in that order.  There are two *main* methods for optimizing hyperparameters:  grid search and random search.  Grid search iterates every hyperparameter over a given range of values and selects the parameters from the list that return the highest accuracy (or any other metric you want to use). For the simpler models that train quickly (like logistic regression), grid search will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest hyperparameters found: \u001b[0;0m\n",
      "{'C': 0.2, 'max_iter': 50, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_C = list(np.arange(0.2, 4, 0.2))\n",
    "base_iter = list(range(50, 300, 50))\n",
    "param_grid = {'C': base_C, 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga'],\n",
    "             'max_iter': base_iter}\n",
    "grid = GridSearchCV(LogisticRegression(random_state=rando_seed), param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_bi, y_bi)\n",
    "log_best_params = grid.best_params_\n",
    "bold_print(\"Best hyperparameters found: \")\n",
    "print(log_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, instead of using the \"balanced\" weight a search is done by varying the weights themselves.  In other projects I've had some interesting (and preferable) results on binary classification problems by allowing the weight of one label to range from small-ish (0.1 and above) to large-ish (20 or so) while the other remains constant.  Both the data and model type (log reg) are relatively un-extraordinary so I'm not expecting to need those extremes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d900a31c18349ff95d6c9b8b9bc2ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "It took 441.57 seconds to complete this search.\n"
     ]
    }
   ],
   "source": [
    "increment = 0\n",
    "base = []\n",
    "acc = []\n",
    "f1 = []\n",
    "t0 = time.time()\n",
    "for num in tqdm_notebook(range(40)):\n",
    "    increment+=0.1\n",
    "    clf = LogisticRegression(**log_best_params, \n",
    "                             class_weight={0: 1, 1: increment}, random_state=rando_seed)\n",
    "    test_grid = strat_kfold(clf, X_bi, y_bi, num_folds=3, random_state=rando_seed)\n",
    "    acc_, f1_ = avg_kfold_metrics(test_grid, return_tuple=True)\n",
    "    base.append(increment)\n",
    "    acc.append(acc_)\n",
    "    f1.append(f1_)\n",
    "t1 = time.time()\n",
    "print(f\"\\n\\nIt took {round(t1-t0, 2)} seconds to complete this search.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(base, acc, linewidth=2, marker='o')\n",
    "plt.plot(base, f1, linewidth=2, marker='o')\n",
    "plt.legend(['ACCURACY', 'F1'], loc='upperright')\n",
    "plt.title('ACCURACY and F1 vs CLASS WEIGHT MULTIPLIER')\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging by the graph, the maximum accuracy is reached around a multiplier of 0.9 and the maximum F1 score is reached around a multiplier around 1.1 or so.  Based on this, a weight multiplier of 1.0 seems a pretty fair medium.  This is consistent with the two untuned models generated, wherein the model trained with 'balanced\" class weights performed *worse* than the simple model with a 1:1 label weight ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average crossval scores for best model: \n",
      "               AVG       STD\n",
      "Accuracy  0.801939  0.006362\n",
      "F1        0.839441  0.005511\n",
      "\n",
      "Time to train model on each fold was 1.84 seconds average.\n"
     ]
    }
   ],
   "source": [
    "logbest = LogisticRegression(**log_best_params, random_state=rando_seed)\n",
    "train_and_report(logbest, 5, X_bi, y_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tuned model is literally super mega slightly better than the first one with no tuning.  Totes worth it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nb\"></a>\n",
    "## Naive-Bayes Classifier\n",
    "\n",
    "Due to the imbalance of gender in our dataset, my intuition tells me that using a complement Naive-Bayes model will give the best results.  Despite this, Naive-Bayes methods in general are extremely fast to train so there's really no reason not to train the whole gamut of Naive-Bayes models just to see.\n",
    "\n",
    "### Complement Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.709807  0.001796\n",
      "F1        0.747301  0.001808\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.708471  0.007372\n",
      "F1        0.746041  0.008385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "\n",
    "clf = ComplementNB()\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_bi, y_bi, train_metrics=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.721071  0.001754\n",
      "F1        0.769839  0.001637\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.719947  0.005861\n",
      "F1        0.768791  0.006472\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_bi, y_bi, train_metrics=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.710822  0.001465\n",
      "F1        0.759459  0.001363\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.710708  0.004440\n",
      "F1        0.759195  0.006217\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_bi, y_bi, train_metrics=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.597083  0.000443\n",
      "F1        0.739546  0.000431\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.594825  0.003285\n",
      "F1        0.737995  0.002651\n"
     ]
    }
   ],
   "source": [
    "X_bi_dummies = pd.get_dummies(X_bi)\n",
    "\n",
    "clf = BernoulliNB()\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_bi_dummies, y_bi, train_metrics=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yeah, complement Naive-Bayes didn't work better than the other Naive-Bayes methods.  Multinomial worked the best with all other methods coming in close behind.  All methods exhibit minimal overfitting and trained fast--unfortunately, their performance is weak, too, so speed doesn't really matter.\n",
    "\n",
    "### Tuning the Multinomial Naive-Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest hyperparameters found: \u001b[0;0m\n",
      "{'alpha': 0.25}\n"
     ]
    }
   ],
   "source": [
    "base = list(np.arange(0.0, 1, 0.05))\n",
    "param_grid = {'alpha': base}\n",
    "grid = GridSearchCV(MultinomialNB(), param_grid, cv=5)\n",
    "grid.fit(X_bi, y_bi)\n",
    "nb_best_params = grid.best_params_\n",
    "bold_print(\"Best hyperparameters found: \")\n",
    "print(nb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average crossval scores for best model: \n",
      "               AVG       STD\n",
      "Accuracy  0.719947  0.005861\n",
      "F1        0.768791  0.006472\n",
      "\n",
      "Time to train model on each fold was 0.16 seconds average.\n"
     ]
    }
   ],
   "source": [
    "nbbest = MultinomialNB(**nb_best_params)\n",
    "train_and_report(nbbest, 5, X_bi, y_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, still not that great for accuracy but worth trying just because of how quick it is.  It should also be noted that naive Bayesian methods really shine in situations where you have small datasets and limited features--which isn't this dataset, but it still has it's place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"svm\"></a>\n",
    "## Support Vector Machines\n",
    "\n",
    "The next class of \"old school\" models is support vector machines--although SVMs aren't nearly as \"old school\" as logistic regression or Naive-Bayes.  SVMs aren't nearly as fast to train as the them, either, especially on datasets bigger than 5 - 10k rows of data.  We will only test a linear, quadratic, and radial basis function kernels here although there are many more kernels possible.  If I had a super computer or a ton of time on my hands I would include a large list of kernels with the other parameters in grid search optimization--but I don't, so I won't.  As with previous models, multiple will be built and the best will be selected for tuning.  Due to the extremely long training times for SVMs of this type, we will use a subset of the entire training data to select the best model and then train that final best model on the entire dataset.\n",
    "\n",
    "Due to the time it takes to train each SVC, below the data is sampled to a quarter size.  This quartered dataset will be used to train and tune the SVCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12069 points of data in this subset.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_X, X_sub, _y, y_sub = train_test_split(X_bi, y_bi, stratify=y_bi, test_size=0.25, random_state=rando_seed)\n",
    "print(f\"There are {len(X_sub)} points of data in this subset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC\n",
    "\n",
    "LinearSVC is the best of the SVC options in scikit-learn because it scales way better than SVC itself.  LinearSVC can scale up with more features and more rows of data linearly while the generic SVC model scales on the order of O(n<sup>2</sup>).  Unfortunately, not all data is simply linearly separable and sometimes you need to branch out into other kernels to get solid results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLinear SVC with balanced weights: \u001b[0;0m\n",
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.596156  0.023583\n",
      "F1        0.572613  0.134976\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.589527  0.025372\n",
      "F1        0.564797  0.139260\n",
      "\u001b[1m\n",
      "\n",
      "Linear SVC with normal weights: \u001b[0;0m\n",
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.654954  0.127781\n",
      "F1        0.605514  0.265109\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.651647  0.122213\n",
      "F1        0.604970  0.256887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "bold_print('Linear SVC with balanced weights: ')\n",
    "clf = LinearSVC(class_weight='balanced', random_state=rando_seed)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_sub, y_sub, num_folds=3, train_metrics=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)\n",
    "bold_print('\\n\\nLinear SVC with normal weights: ')\n",
    "clf = LinearSVC(random_state=rando_seed)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_sub, y_sub, num_folds=3, train_metrics=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBinomial SVC with balanced weights: \u001b[0;0m\n",
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.924310  0.000786\n",
      "F1        0.935897  0.000640\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.791532  0.000550\n",
      "F1        0.823511  0.000826\n",
      "\u001b[1m\n",
      "\n",
      "Binomial SVC with normal weights: \u001b[0;0m\n",
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.926009  0.001169\n",
      "F1        0.939236  0.000911\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.794681  0.002645\n",
      "F1        0.832044  0.002294\n"
     ]
    }
   ],
   "source": [
    "bold_print(\"Binomial SVC with balanced weights: \")\n",
    "clf = SVC(kernel='poly', degree=2, class_weight='balanced', random_state=rando_seed)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_sub, y_sub, num_folds=3, train_metrics=True, \n",
    "                                            random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)\n",
    "bold_print('\\n\\nBinomial SVC with normal weights: ')\n",
    "clf = SVC(kernel='poly', degree=2, random_state=rando_seed)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_sub, y_sub, num_folds=3, train_metrics=True, \n",
    "                                            random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial Basis Function Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRBF with balanced weights: \u001b[0;0m\n",
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.939473  0.001227\n",
      "F1        0.948957  0.001038\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.804540  0.003086\n",
      "F1        0.835208  0.002558\n",
      "\u001b[1m\n",
      "\n",
      "RBF with normal weights: \u001b[0;0m\n",
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.939183  0.001367\n",
      "F1        0.950079  0.001089\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.809263  0.002794\n",
      "F1        0.845892  0.002438\n"
     ]
    }
   ],
   "source": [
    "bold_print('RBF with balanced weights: ')\n",
    "clf = SVC(kernel='rbf', class_weight='balanced', random_state=rando_seed)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_sub, y_sub, num_folds=3, train_metrics=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)\n",
    "bold_print('\\n\\nRBF with normal weights: ')\n",
    "clf = SVC(kernel='rbf', random_state=rando_seed)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_sub, y_sub, num_folds=3, train_metrics=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it appears that there is no consistent weighting scheme that is best between kernels, so both will have to be used to tune.  RBF and binomial SVCs also greatly outperformed linear so linear will be excluded from the tuning to decrease tuning time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the SVM\n",
    "\n",
    "Looking above, it's clear that our SVM with the radial basis function kernel performs the best (followed very closely by the quadratic SVC).  It is a fair amount overfit but still outperforms every other model so far on the crossvalidation score so further tuning will be done on just these two kernels to decrease tuning time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest hyperparameters found: \u001b[0;0m\n",
      "{'C': 10, 'class_weight': None, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "It took 1505.5 seconds to complete search.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "\n",
    "def rand_list(lower, upper, sample_size, random_seed=None):\n",
    "    rand = []\n",
    "    random.seed(random_seed)\n",
    "    for i in range(sample_size):\n",
    "        rand.append(random.uniform(lower, upper))\n",
    "    return rand\n",
    "        \n",
    "num_iterations = 60\n",
    "hyperparams = {'kernel': ['poly', 'rbf'], \n",
    "              'C':[0.001, 0.01, 0.1, 1, 10],\n",
    "              'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "\n",
    "t0 = time.time()\n",
    "rando_search = GridSearchCV(SVC(random_state=rando_seed, degree=2), hyperparams, cv=3, n_jobs=-1)\n",
    "rando_search.fit(X_sub, y_sub)\n",
    "bold_print(\"Best hyperparameters found: \")\n",
    "svc_best_params = rando_search.best_params_\n",
    "print(svc_best_params)\n",
    "t1 = time.time()\n",
    "print(f\"\\nIt took {round(t1-t0,2)} seconds to complete search.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Long Wait!](https://media.giphy.com/media/tXL4FHPSnVJ0A/giphy.gif)\n",
    "\n",
    "The final SVC will only be trained on a half the data instead of all data due to training time.  These SVCs take for - ev - er to train and for the simple model exploration happening here it's not worth it to me to spend $4 worth of cloud compute just to get a full accuracy measure that could be approximated in much less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average crossval scores for best model: \n",
      "               AVG       STD\n",
      "Accuracy  0.808750  0.005240\n",
      "F1        0.843972  0.004543\n",
      "\n",
      "Time to train model on each fold was 102.96 seconds average.\n"
     ]
    }
   ],
   "source": [
    "X_half, _, y_half, _ = train_test_split(X_bi, y_bi, test_size=0.5, stratify=y_bi)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(**svc_best_params, random_state=rando_seed)\n",
    "train_and_report(svm_clf, 3, X_half, y_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEST PERFORMER SO FAR (barely but on half the data)! Unfortunately, the bane of my existence in terms of training time.  The differential between train and test averages indicates that there is a decent amount of overfitting occuring with this model but, fortunately, even on the test data it does better than everything so far (which is what really counts).</br>\n",
    "![YES!](https://media.giphy.com/media/UbD6c9YyD0SPu/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='knn'></a>\n",
    "## K-Nearest Neighbors \n",
    "\n",
    "K-nearest neighbors is a (relatively) quick and easy classification method that basically compares the answers between tests and decides if it is a male or female based on which other testers the answers are closest to.  There are multiple metrics available but using L1 (\"Manhattan metric\") is chosen off the bat as it allows for comparing differences of answers *within* questions.  Previous experience using a KNN classifier is not that great, however, and I don't expect this to work as well as other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.799983  0.001359\n",
      "F1        0.840333  0.001258\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.687549  0.013238\n",
      "F1        0.752128  0.008254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5, p=2, n_jobs=-1)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_sub, y_sub, train_metrics=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest hyperparameters found: \u001b[0;0m\n",
      "{'n_neighbors': 16, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "n_neigh = [2, 4, 8, 16]\n",
    "metric = [1, 2]\n",
    "c_weights = ['uniform', 'distance']\n",
    "param_grid = {'n_neighbors': n_neigh, 'p': metric, 'weights': c_weights}\n",
    "grid = GridSearchCV(KNeighborsClassifier(algorithm='auto'), param_grid, cv=3, n_jobs=-1)\n",
    "grid.fit(X_sub, y_sub)\n",
    "knn_best_params = grid.best_params_\n",
    "bold_print(\"Best hyperparameters found: \")\n",
    "print(knn_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, half the dataset is used to train the KNN classifier because it takes too long for a simple exploration of models on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average crossval scores for best model: \n",
      "               AVG       STD\n",
      "Accuracy  0.733371  0.009402\n",
      "F1        0.787101  0.009031\n",
      "\n",
      "Time to train model on each fold was 153.78 seconds average.\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(algorithm='auto', **knn_best_params, n_jobs=-1)\n",
    "train_and_report(knn_clf, 5, X_bi, y_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sooooo, yeah.  Not great.  I'd rather trade the slight increase in accuracy for the massive increase in speed and go with a Naive-Bayes model instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trees\"></a>\n",
    "## Ensemble Decision Trees\n",
    "\n",
    "Next up are my favorite class of traditional models:  ensemble decision trees.  Random forests and gradient boosted trees will both be looked at and I expect them to outperform all previous models on our large, tabular dataset.  Training time unfortunately sucks for these (though *usually* not as bad as SVMs) as well, so I predict some boredom in the coming minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Random forest classifiers are an excellent choice for data such as this.  The main danger that will be run in to is the tendency to overfit--the accuracy on the training data will likely be close to 1.0 but not nearly that high on the test set without significant tuning to the model.  We will start off with a simple random forest of 100 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a144a9dee84c1d94b0ee9d6aa86d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "          AVG  STD\n",
      "Accuracy  1.0  0.0\n",
      "F1        1.0  0.0\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.769325  0.006762\n",
      "F1        0.821980  0.004901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_sub, y_sub, num_folds=5, train_metrics=True, \n",
    "                                            verbose=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted\n",
    "\n",
    "I expect the gradient boosted decision tree to train faster than the random forest classifier but the predictive power is usually hit-or-miss compared to random forests without significant tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b067162fc1d740fca49788d7643837ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.983470  0.001187\n",
      "F1        0.986157  0.001008\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.798576  0.007299\n",
      "F1        0.831600  0.005846\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "clf = LGBMClassifier(n_estimators=200, class_weight='balanced', random_state=rando_seed, n_jobs=-1)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_sub, y_sub, num_folds=5, train_metrics=True, \n",
    "                                            verbose=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Gradient Boosted Model\n",
    "\n",
    "Ensemble decision trees have a higher training time than simple methods like logistic regression as well as many more hyperparameters--each over a large range.  This makes performing a grid search over hyperparameters extremely time and resource intensive.  Luckily, James Bergstra and Yoshua Bengio have shown that random searches can match or beat the performance of a grid search in a large number of cases<sup>[[1]](#berg_beng)</sup>.  The random search method is what we'll use to tune our categorical gradient boosted model below.  The beauty with random search is that testing only 60 random hyperparameter combinations is enough to get within 5% of the model's max accuracy with 95% confidence.\n",
    "<br/>\n",
    "<br/>\n",
    "<a id=\"berg_beng\"></a>\n",
    "    [1] Bergstra, J. & Bengio, Y. Random Search for Hyper-Parameter Optimization. *Journal of Machine Learning Research* 13: 281-305, 2012.  Retrieved from &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest hyperparameters found: \u001b[0;0m\n",
      "{'num_leaves': 125, 'n_estimators': 879, 'max_depth': 10, 'max_bin': 6, 'loss_function': 'Logloss', 'learning_rate': 0.23373481573160126}\n",
      "\n",
      "It took 201.71 seconds to complete search.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import random\n",
    "\n",
    "def rand_list(lower, upper, sample_size, random_seed=None):\n",
    "    rand = []\n",
    "    random.seed(random_seed)\n",
    "    for i in range(sample_size):\n",
    "        rand.append(random.uniform(lower, upper))\n",
    "    return rand\n",
    "\n",
    "num_iterations = 60\n",
    "hyperparams = {'max_depth':list(range(1, 16)), \n",
    "              'loss_function': ['Logloss', 'CrossEntropy'], \n",
    "              'num_leaves':list(range(2, 150)),\n",
    "              'learning_rate': rand_list(.001, 0.3, num_iterations, random_seed=rando_seed+42),\n",
    "              'n_estimators': list(range(20, 1200)),\n",
    "              'max_bin': [2,3,4,5,6]}\n",
    "\n",
    "t0 = time.time()\n",
    "rando_search = RandomizedSearchCV(LGBMClassifier(random_state=rando_seed), hyperparams, \n",
    "                                  random_state=rando_seed+72, n_iter=num_iterations, cv=3, n_jobs=-1)\n",
    "rando_search.fit(X_sub, y_sub)\n",
    "bold_print(\"Best hyperparameters found: \")\n",
    "grad_tree_best_params = rando_search.best_params_\n",
    "print(grad_tree_best_params)\n",
    "t1 = time.time()\n",
    "print(f\"\\nIt took {round(t1-t0,2)} seconds to complete search.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average crossval scores for best model: \n",
      "               AVG       STD\n",
      "Accuracy  0.816171  0.006028\n",
      "F1        0.851206  0.005193\n",
      "\n",
      "Time to train model on each fold was 12.46 seconds average.\n"
     ]
    }
   ],
   "source": [
    "bestgrad = LGBMClassifier(silent=True, random_state=rando_seed, **grad_tree_best_params)\n",
    "train_and_report(bestgrad, 5, X_bi, y_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Gradient Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c110686904244b08b99c47fd8f43132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.913850  0.002058\n",
      "F1        0.929759  0.001604\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.803878  0.003125\n",
      "F1        0.841411  0.002201\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "X_bi_cat = X_bi.astype('category')\n",
    "X_sub_cat = X_sub.astype('category')\n",
    "\n",
    "clf = CatBoostClassifier(n_estimators=200, silent=True, random_state=rando_seed)\n",
    "kwargs = {'silent': True}\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_sub_cat, y_sub, num_folds=5, train_metrics=True, \n",
    "                                            verbose=True, fit_kwargs=kwargs, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hhmmm, interesting.  The random forest was waaaay overfit (unsurprisingly, random forests take a decent amount of tuning to keep from overfitting) while the gradient boosted tree was not-quite-as overfit (hehe, just kidding--it was definitely overfit too).  Counter to my initial intuition, the gradient boosted tree did better on the test set right out of the box.  The real shocker is that the categorical gradient boosted tree did better than both in terms of accuracy and was much less overfit (but still somewhat overfit).\n",
    "\n",
    "Below, we \"shrink\" the categorical variables by reducing gradation in answers for each feature.  Instead of \"disagree\" and \"slightly disagree\" will be binned together, \"neither agree nor disagree\" and \"no answer\" will stay their own category, and \"agree\" or \"slightly agree\" will be binned together.  CatBoostClassifier will then be applied to these new categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>P9</th>\n",
       "      <th>P10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42884</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36053</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37399</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25550</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38483</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 ... P1 P2 P3 P4 P5 P6 P7 P8 P9 P10\n",
       "42884  3  3  3  3  3  3  2  2  1   2 ...  3  1  3  3  1  3  3  2  2   1\n",
       "36053  1  2  2  2  3  2  2  2  2   2 ...  3  2  3  3  2  2  2  1  2   2\n",
       "37399  3  3  3  3  3  3  3  1  1   1 ...  1  1  3  3  1  1  3  3  3   3\n",
       "25550  3  3  3  3  3  3  3  3  1   1 ...  3  2  1  3  3  1  1  1  1   1\n",
       "38483  3  3  3  3  3  2  3  3  1   1 ...  3  3  2  2  1  1  2  1  3   2\n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shrink(num):\n",
    "    if (num==1) or (num==2):\n",
    "        return 1\n",
    "    elif (num==3):\n",
    "        return 2\n",
    "    elif (num>3):\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "X_sub_shrink = X_sub.copy()\n",
    "X_sub_shrink = X_sub_shrink.applymap(shrink)\n",
    "X_sub_shrink = X_sub_shrink.astype('category')\n",
    "X_sub_shrink.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cddabe19cf440cb87919c012717394b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\n",
      "\n",
      "Training crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.902332  0.001781\n",
      "F1        0.920595  0.001439\n",
      "\u001b[1m\n",
      "\n",
      "Testing crossvalidation metrics average: \u001b[0;0m\n",
      "               AVG       STD\n",
      "Accuracy  0.786645  0.003725\n",
      "F1        0.828332  0.002225\n"
     ]
    }
   ],
   "source": [
    "clf = CatBoostClassifier(n_estimators=200, silent=True, random_state=rando_seed)\n",
    "train_metrics, test_metrics = strat_kfold(clf, X_sub_shrink, y_sub, num_folds=5, train_metrics=True, \n",
    "                                            verbose=True, random_state=rando_seed)\n",
    "train_test_eval(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Super cool**.  Removing all gradation in each sentiment results in a net loss of only 1.5% crossvalidation accuracy!  What this means is that just the sentiment itself--and not gradation--carry almost all of the information in the dataset.  This is important to note for model tuning, as removing sentiment gradation prior to tuning hyperparameters (for example, adding depth and n_estimators--each of which tend to cause more overfitting as they increase) may help us increase crossvalidation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Categorical Gradient Boosted Model\n",
    "\n",
    "As with SVCs above, ensemble tree methods come with a lot of hyperparameters and higher training time so all will be tuned with random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest hyperparameters found: \u001b[0;0m\n",
      "{'n_estimators': 858, 'loss_function': 'Logloss', 'learning_rate': 0.12046437963028535, 'l2_leaf_reg': 61, 'depth': 4}\n",
      "\n",
      "It took 24501.67 seconds to complete search.\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 60\n",
    "hyperparams = {'depth':list(range(1, 16)), \n",
    "              'loss_function': ['Logloss', 'CrossEntropy'], \n",
    "              'l2_leaf_reg':list(range(2, 64)),\n",
    "              'learning_rate': rand_list(.001, 0.3, num_iterations, random_seed=rando_seed+42),\n",
    "              'n_estimators': list(range(20, 1200))}\n",
    "\n",
    "t0 = time.time()\n",
    "rando_search = RandomizedSearchCV(CatBoostClassifier(silent=True, random_state=rando_seed), hyperparams, \n",
    "                                  random_state=rando_seed+72, n_iter=num_iterations, cv=3, n_jobs=-1)\n",
    "rando_search.fit(X_sub_cat, y_sub)\n",
    "bold_print(\"Best hyperparameters found: \")\n",
    "cat_tree_best_params = rando_search.best_params_\n",
    "print(cat_tree_best_params)\n",
    "t1 = time.time()\n",
    "print(f\"\\nIt took {round(t1-t0,2)} seconds to complete search.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average crossval scores for best model: \n",
      "               AVG       STD\n",
      "Accuracy  0.816233  0.005761\n",
      "F1        0.850406  0.005274\n",
      "\n",
      "Time to train model on each fold was 27.95 seconds average.\n"
     ]
    }
   ],
   "source": [
    "bestcat = CatBoostClassifier(silent=True, random_state=rando_seed, **cat_tree_best_params)\n",
    "train_and_report(bestcat, 5, X_bi, y_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eh, overall accuracy not that great but about on par with the other models.  F1 score is definitely on the higher end of models (which is good), but overall accuracy is definitely not worth the extra tuning time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## Conclusions\n",
    "\n",
    "From this big trip around the zoo of models, three classes of models really stand out in terms of performance against the rest: logarithmic regression, support vector classifiers, and ensemble decision trees (specifically both gradient boosted ones).  Logarithmic regression and SVCs ended up in the 80 - 81% accuracy range and both the categorical and normal gradient boosted trees ended up in the 81 - 82% accuracy range.\n",
    "\n",
    "Of these, logarithmic regression was by far the fastest to train, followed by normal gradient boosted decision trees.  SVCs and categorical gradient boosted trees both took way too long to train--so long, in fact, that the final tuned SVC was only trained on half the data so as to not waste a ton of money on simple model exploration.  This is a good indication that logarithmic regression and gradient boosted trees are solid avenues of approach for building a more predictive model--along with additional data processing techniques like actually dealing with missing values in the personality questions and better encoding of the variables.  Additionally, with the categorical gradient boosted model there was minimal accuracy loss for significantly compacting the answer categories for each question--which may make it a reasonable approach to take when building a final model in order to combat overfitting.\n",
    "<br/>\n",
    "<br/>\n",
    "![Goodbye!](https://media0.giphy.com/media/YC2ohKyxNlXq0/giphy.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
