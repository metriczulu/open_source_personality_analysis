{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model for Gender Using Traditional Methods\n",
    "\n",
    "As opposed with the first two notebooks, this notebook will focus just on making a decent model to predict gender.  There will not be any exploration in this one, it is solely moving forward with creating a decently predictive model--although, there was **a lot** of exploration that happened behind the scenes in a scrap notebook to get to this point.  \n",
    "\n",
    "I really enjoyed this particular dataset and target variable because it's been tough and difficult to get *anything* above 80% accuracy out of it.  I really felt like I was fighting for fractions of a percent and felt extremely proud when I'd manage to pull another percent out of it.  As is almost the standard for tough problems, this model is an ensemble which combines five other tuned models.  Stacking and blending models like this is a great way to break past asymptotic accuracy barriers that are reached using only single models.\n",
    "\n",
    "This overall model was assembled using a logistic regression model, two different support vector classifiers, and two different gradient boosted decision trees.  Multiple methods of predicting the final output from the output of each individual classifier are used and compared at the end--with most getting within 0.5% accuracy of each other (however, like I said, I was fighting this data for crumbs so 0.5% is a lot to me).\n",
    "\n",
    "![hello](https://media.giphy.com/media/Wj7lNjMNDxSmc/giphy.gif)\n",
    "\n",
    "## Table of Contents\n",
    "1. [Load and preprocess data](#data_load)\n",
    "    - [Dealing with missing answers](#missing_vals)\n",
    "    - [A little more data preparation](#more_prep)\n",
    "    \n",
    "+ [Building individual models](#models)\n",
    "    - [Logarithmic Regression model](#logreg)\n",
    "    - [Light Gradient Boosted Model (LGBM)](#lgbm)\n",
    "    - [First Support Vector Classifier (SVC)](#svc1)\n",
    "    - [Second Support Vector Classifier (SVC)](#svc2)\n",
    "    - [XGBoost model](#xgb)\n",
    "    \n",
    "+ [Training the ensemble](#ensemble)\n",
    "    - [Mean of predictions](#mean)\n",
    "    - [Weighted mean of predictions](#weighted_mean)\n",
    "    - [Mode of predictions](#mode)\n",
    "    - [Logarithmic regression ensemble](#logensemble)\n",
    "    - [SVC ensemble](#svcensemble)\n",
    "    - [Decision tree ensemble](#treeensemble)\n",
    "+ [Conclusions](#conclusions)\n",
    "\n",
    "<a id=\"data_load\"></a>\n",
    "## Data loading and preprocessing\n",
    "\n",
    "As usual, this first section simply installs any needed packages and imports any necessary packages, classes, and functions.  The data is loaded into a dataframe and all rows of data with missing or non-binary genders is removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid requirement: ''scikit-learn==0.20.3''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost -q -q -q\n",
    "!pip install 'scikit-learn==0.20.3' -q -q -q\n",
    "!pip install lightgbm -q -q -q\n",
    "!pip install scikit-optimize -q -q -q\n",
    "!pip install numpy --upgrade -q -q -q\n",
    "!pip install seaborn -q -q -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>sqrtbox_age</th>\n",
       "      <th>box_accuracy</th>\n",
       "      <th>box_elapsed</th>\n",
       "      <th>bin_age</th>\n",
       "      <th>bin_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>US</td>\n",
       "      <td>5</td>\n",
       "      <td>914</td>\n",
       "      <td>1.683215</td>\n",
       "      <td>2.270186</td>\n",
       "      <td>9.774004</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>891</td>\n",
       "      <td>1.900242</td>\n",
       "      <td>2.287068</td>\n",
       "      <td>9.723672</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>US</td>\n",
       "      <td>5</td>\n",
       "      <td>903</td>\n",
       "      <td>1.853102</td>\n",
       "      <td>2.240760</td>\n",
       "      <td>9.750076</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>806</td>\n",
       "      <td>1.861649</td>\n",
       "      <td>2.272403</td>\n",
       "      <td>9.526909</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>NZ</td>\n",
       "      <td>0</td>\n",
       "      <td>1826</td>\n",
       "      <td>1.956691</td>\n",
       "      <td>2.258593</td>\n",
       "      <td>11.190933</td>\n",
       "      <td>4</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  ...  gender  accuracy  country  \\\n",
       "0   1   4   2   3   3   2   3   4   4    3  ...       1        92       US   \n",
       "1   4   3   4   3   4   4   4   4   2    2  ...       1       100       US   \n",
       "2   3   4   4   4   4   4   4   3   2    2  ...       1        80       US   \n",
       "3   4   5   4   4   4   3   3   2   2    2  ...       1        93       US   \n",
       "4   4   0   4   4   4   3   5   1   2    4  ...       2        87       NZ   \n",
       "\n",
       "   source  elapsed  sqrtbox_age  box_accuracy  box_elapsed  bin_age  \\\n",
       "0       5      914     1.683215      2.270186     9.774004        0   \n",
       "1       0      891     1.900242      2.287068     9.723672        4   \n",
       "2       5      903     1.853102      2.240760     9.750076        3   \n",
       "3       0      806     1.861649      2.272403     9.526909        3   \n",
       "4       0     1826     1.956691      2.258593    11.190933        4   \n",
       "\n",
       "   bin_country  \n",
       "0           US  \n",
       "1           US  \n",
       "2           US  \n",
       "3           US  \n",
       "4        Other  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import pickle\n",
    "import copy\n",
    "import itertools\n",
    "from scipy import stats\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def pct(num):\n",
    "    return int(round(num*10000))/100.00\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#sklearn kind of sucks and puts out a lot of metric warnings--especially when you have an extreme minority class that may\n",
    "#not get predicted.\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "df = pd.read_csv('data_trans.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gender.value_counts(dropna=False)\n",
    "og_count = df.shape[0]\n",
    "df = df[df.gender!=0]\n",
    "\n",
    "non_features = ['age', 'accuracy', 'elapsed', 'gender', 'source', 'country',\n",
    "               'sqrtbox_age', 'box_accuracy', 'box_elapsed', 'bin_age', 'bin_country']\n",
    "\n",
    "# create a copy dataset but drop all non-binary genders (which makes it a binary classification problem)\n",
    "# re-code binary variables to be 0/1 instead of 1/2\n",
    "X = df.drop(non_features, axis=1)\n",
    "y = df.gender\n",
    "X = X[y>0]\n",
    "y = y[y>0]\n",
    "X = X[y<3]\n",
    "y = y[y<3]\n",
    "y = y-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"missing_vals\"></a>\n",
    "### Dealing with missing data\n",
    "\n",
    "First things first, we must deal with missing data.  Below is a distribution plot for how many rows are missing values for all of the columns.  Considering there is almost 40k rows of data total, each column missing a few hundred values doesn't seem to be that significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot([X[col].value_counts()[0] for col in X.columns], color='seagreen')\n",
    "plt.xlabel(\"Number of missing values per column\")\n",
    "plt.title(\"Distribution of missing values by column\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.70907132351418% of the rows have at least one missing question in the dataset.\n",
      "There are 34897 rows of data with no missing questions.\n"
     ]
    }
   ],
   "source": [
    "# the below function counts the number of missing values in each row\n",
    "def missing_count(row, missing_val=0):\n",
    "    vals = set(row.unique())\n",
    "    if 0 in vals: vals.remove(0)\n",
    "    else: return 0\n",
    "    flatten_dict = {x:0 for x in vals}\n",
    "    flatten_dict[0] = 1\n",
    "    return row.replace(flatten_dict).sum()\n",
    "\n",
    "has_zeros = X.apply(missing_count, axis=1)\n",
    "zero_count = has_zeros.value_counts()\n",
    "print(f\"{pct(len(X)-zero_count[0])/len(has_zeros)}% of the rows have at least one missing question in the dataset.\")\n",
    "print(f\"There are {zero_count[0]} rows of data with no missing questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(has_zeros[has_zeros>1], color='maroon', alpha=0.8)\n",
    "plt.title(\"Distribution of missing values by row\", fontsize=16)\n",
    "plt.xlabel(\"Number of missing values\", fontsize=14)\n",
    "plt.ylabel(\"Number of rows with missing values\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "bins = np.geomspace(2, 163, 10)\n",
    "int_bins = [int(i) for i in bins]\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(has_zeros, bins=bins, color='seagreen', alpha=0.8)\n",
    "plt.title(\"Distribution of missing values for rows with 2 or more missing values in logscale\", fontsize=16)\n",
    "plt.xlabel(\"Number of missing values\", fontsize=14)\n",
    "plt.ylabel(\"Number of rows with missing values\", fontsize=14)\n",
    "plt.xticks(int_bins, rotation=90, fontsize=9)\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the missing data\n",
    "\n",
    "Clearly, the vast majority of rows of data are missing only one value or less.  My first instinct was to drop all rows that were missing more than one answer but, through experimentation with the data, I realized that dropping all rows of data gives--by far--the best performance boost over almost every alternate method (from specially encoding missing values to using complex imputation techniques).  For this reason, I end up setting the cut-off level for removing a row to be *any* missing answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 34897 rows with 0 or fewer missing answers.\n"
     ]
    }
   ],
   "source": [
    "cut_off = 0\n",
    "X_drop = X[has_zeros<=cut_off]\n",
    "y_drop = y[has_zeros<=cut_off]\n",
    "print(f\"The data has {len(X_drop)} rows with {cut_off} or fewer missing answers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"more_prep\"></a>\n",
    "### A little more data preparation\n",
    "\n",
    "This section is a quick section to prep the data before training.  The class defined in the next block transforms our ordinal variables into a decent form for use with logistic regression.  This is an encoding method I developed on my own with which I've noticed consistent better performance with ordinal variables on logistic regression (and neural networks--but that's a later notebook).  This method works similar to one-hot encoding, but instead of all columns being zero except for the category we want to represent, the ordinal category we wish to represent and all categories less than it are encoded with a one and all higher ordinal categories are zero.  There are solid mathematical reasons why this works by allowing the process of minimizing the loss function of our logistic regression system to encode the optimal distance between each ordinal variable--but that is also another notebook.  I plan on doing a workthrough notebook and a short write-up on the method and uploading it to my GitHub at some point in the future.\n",
    "\n",
    "As a quick example, if the column being transformed can be missing values (0) or one of two ordinals (1 or 2), the encoder will transform each as follows:\n",
    "\n",
    "        0  ->  [0, 0]\n",
    "        1  ->  [1, 0]\n",
    "        2  ->  [1, 1]\n",
    "\n",
    "After the encoding class is defined, the data is split into a training, validation, and testing set and an ordinal dummy encoding done on a copy of each.  I am using a three-way split so that the individual models can be tuned using crossvalidation and resampling techniques on just the training set and then the ensemble model will be trained on the validation set.  Training the ensemble on a different set than the individual models is necessary to avoid serious data leakage. Training and tuning the ensemble model on the same training set that the individual models were trained was estimating my final accuracy to be nearly 100% but only giving me 79 - 80% on the actual test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalDummyEncoder:\n",
    "    \n",
    "    def __init__(self, impute_missing=None):\n",
    "        # impute_missing is a simple variable that lets you impute the mean or mode into missing values as\n",
    "        # it encodes each column\n",
    "        # using \"mean\" gives an interesting result because it encodes missing values as the expected value of the variable\n",
    "        self.impute_missing = impute_missing\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # added to be compatible with scikit-learn encoders.  Unused because nothing needs to be fit.\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, X, cols=None, verbose=False):\n",
    "        # added to be compatible with scikit-learn encoders.  Just transforms because nothing needs to be fit.\n",
    "        return self.transform(X, cols=cols, verbose=verbose)\n",
    "    \n",
    "    def transform(self, X_vals, cols=None, verbose=False):\n",
    "        # transforms the the df to ordinal dummy encoded variables as described above\n",
    "        # if cols=None, transform every column.  Else, transform the columns with names in 'cols'\n",
    "        X = X_vals.copy()\n",
    "        first_col = True\n",
    "        if cols: columns=cols\n",
    "        else: columns=X.columns\n",
    "        for col in tqdm_notebook(columns, disable=(not verbose)):\n",
    "            trans_col = self.__column_transformer(X[col])\n",
    "            if first_col:\n",
    "                new_df = trans_col\n",
    "                first_col=False\n",
    "            else:\n",
    "                new_df = pd.concat([new_df, trans_col], axis=1)\n",
    "        return new_df\n",
    "    \n",
    "    def __column_transformer(self, column):\n",
    "        # encodes a single column\n",
    "        if 0 in column.unique():\n",
    "            num_new_cols = len(column.unique())\n",
    "        else:\n",
    "            num_new_cols = len(column.unique())+1\n",
    "        col_length = len(column)\n",
    "        new_col_array = np.zeros((col_length, num_new_cols-1), dtype=int)\n",
    "        row_count=0\n",
    "        indexes = []\n",
    "        for index, row in column.iteritems():\n",
    "            col_index = row-1\n",
    "            if col_index>=0:\n",
    "                num_last_zs = num_new_cols-row\n",
    "                encoded = [1]*row + [0]*(num_last_zs-1)\n",
    "                new_col_array[row_count] = encoded\n",
    "            row_count+=1\n",
    "            indexes.append(index)\n",
    "        returned = pd.DataFrame(new_col_array, columns=[column.name+'_'+str(i) for i in range(1,num_new_cols)], index=indexes)\n",
    "        if self.impute_missing==\"mean\" or self.impute_missing==\"mode\":\n",
    "            for col in returned:\n",
    "                if self.impute_missing==\"mean\":\n",
    "                    returned[col][column==0] = returned[col].mean()\n",
    "                elif self.impute_missing==\"mode\":\n",
    "                    returned[column==0] = returned[col].mode()\n",
    "        return returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_, y_train, y_ = train_test_split(X_drop, y_drop, test_size=0.7, stratify=y_drop, random_state=12)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_, y_, test_size=0.66, stratify=y_, random_state=36)\n",
    "\n",
    "ord_encoder = OrdinalDummyEncoder()\n",
    "X_train_ord = ord_encoder.transform(X_train)\n",
    "X_test_ord = ord_encoder.transform(X_test)\n",
    "X_val_ord = ord_encoder.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below block just gives me a simple method to save the exact data splits and models so that I could experiment with the final ensemble on my laptop and save some of my precious free AWS time.  It will also help in a future notebook where I plan on using an ensemble that combines these traditional models with deep learning techniques.  Keeping the same exact models and data splits will allow me to make direct comparisons between methods in future notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(obj, name, file_type=None):\n",
    "    if file_type is None:\n",
    "        file_type = \".data\"\n",
    "    file = open(name+file_type, 'wb')\n",
    "    pickle.dump(obj, file)\n",
    "    file.close()\n",
    "\n",
    "def load_pickle(name):\n",
    "    file = open(name, 'rb')\n",
    "    r = pickle.load(file)\n",
    "    file.close()\n",
    "    return r\n",
    "\n",
    "save_pickle(X_train, \"X_train\")\n",
    "save_pickle(X_test, \"X_test\")\n",
    "save_pickle(X_val, \"X_val\")\n",
    "save_pickle(X_train_ord, \"X_train_ord\")\n",
    "save_pickle(X_test_ord, \"X_test_ord\")\n",
    "save_pickle(X_val_ord, \"X_val_ord\")\n",
    "save_pickle(y_train, \"y_train\")\n",
    "save_pickle(y_test, \"y_test\")\n",
    "save_pickle(y_val, \"y_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>\n",
    "## Building individual models\n",
    "\n",
    "Now starts the fun part.  Five different models will be created a tuned.  The goal is to get each individual model to at least 80% so that no single model drags down the overall accuracy of the ensemble.  Granted, a second key component is having models that misclassify differently and don't all behave exactly the same--a big reason I went with two separate SVCs (one polynomial kernel and one radial basis function kernel) to help ensure decision boundaries are distinct between the models.\n",
    "\n",
    "<a id=\"logreg\"></a>\n",
    "### Logarithmic Regression\n",
    "\n",
    "The first model trained is my personal favorite method.  I **looooove** logistic regression for it's speed, ease-of-use, reliability, and it's naturally calibrated probabilities.  I could've simply used scikit-learn's LogisticRegressionCV and saved some time on the following grid search but I wanted to be absolutely confident that there wasn't a better model sitting out there with a different loss function or balanced weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'C': 0.011513953993264481, 'class_weight': None, 'penalty': 'l2'}\n",
      "Best resample accuracy: 81.03%\n"
     ]
    }
   ],
   "source": [
    "base_C = np.logspace(-5, 5, 50)\n",
    "param_grid = {'C': base_C, 'penalty': ['l1', 'l2'], 'class_weight': [None, 'balanced']}\n",
    "logreg_seed = 13\n",
    "grid = GridSearchCV(LogisticRegression(random_state=logreg_seed, max_iter=300), param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train_ord, y_train)\n",
    "log_best_params = grid.best_params_\n",
    "print(\"Best hyperparameters found: \"+str(log_best_params))\n",
    "print(f\"Best resample accuracy: {pct(grid.best_score_)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of best model found: 81.55\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(**log_best_params, random_state=logreg_seed, n_jobs=-1)\n",
    "log_model.fit(X_train_ord, y_train)\n",
    "y_test_preds = log_model.predict(X_test_ord)\n",
    "print(f\"Overall accuracy of best model found: {pct(accuracy_score(y_test, y_test_preds))}\")\n",
    "save_pickle(log_model, \"log_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning with resampling\n",
    "\n",
    "The following class is a quick draft of a full class (well, group of classes) I've made to tune hyperparameters using resampling techniques instead of k-fold crossvalidation.  While resampling tends to underestimate accuracy compared to crossvalidation, it does so *consistently*--a trait which still makes it valuable for hyperparameter tuning.  Specific hyperparameters that maximize crossvalidation accuracy should--in most situations--also maximize accuracy estimated by training and evaluating the model on a large group of samples.  The benefit to this is that hyperparameter tuning using resampling tends to be much faster as each model can be trained on a much smaller sample than each fold is in crossvalidation.\n",
    "\n",
    "If you'd like to see the full implementation of the following randomized search with resampling class as well it's little brother grid search with resampling, you can look into it further on my GitHub [here](https://github.com/metriczulu/tuneRs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSearchResample:\n",
    "    \n",
    "    def __init__(self, model, params, num_iter=60, num_samples=10, sample_size=0.2, test_size=0.3, metric=None, \n",
    "                 random_state=None):\n",
    "        '''\n",
    "        param model:        The model to tune\n",
    "        param params:       A parameter dictionary.  Uses the scikit-optimize variables skopt.Integer, skopt.Categorical, and \n",
    "                            skopt.Real\n",
    "        param num_iter:     Number of random variables to try\n",
    "        param num_samples:  The total number of samples and models trained for each parameter\n",
    "        param sample_size:  The size of samples taken.  Any percentage in (0, 1]\n",
    "        param test_size:    Size of the test size in each sample\n",
    "        param metric:       Scoring metric to evaluate each model.  Defaults to simple accuracy if None\n",
    "        param random_state: Self-explanatory\n",
    "        '''\n",
    "        self.metric = metric\n",
    "        self.num_samples = num_samples\n",
    "        self.sample_size = sample_size\n",
    "        self.test_size = test_size\n",
    "        self.best_params_ = None\n",
    "        self.model = model\n",
    "        if random_state is None:\n",
    "            random_state = np.random.randint(0, 36000)\n",
    "        self.random_state = random_state\n",
    "        self.num_iter = num_iter\n",
    "        self.best_score_ = 0.0\n",
    "        self.best_model = None\n",
    "        self.best_std_ = 0.0\n",
    "        self.params=params\n",
    "        self.param_grid = self.__random_grid(self.random_state+13)\n",
    "        \n",
    "    def __random_grid(self, random_state=None):\n",
    "        # Generates a list of random hyperparameter dictionaries to iterate over\n",
    "        if random_state==None:\n",
    "            random_state = np.random.randint(0, 36000)\n",
    "        np.random.seed(random_state)\n",
    "        random_list = np.random.randint(0, 36000, size=self.num_iter)\n",
    "        param_list = []\n",
    "        for index in range(self.num_iter):\n",
    "            param_list.append({key: self.params[key].rvs(1, random_state=random_list[index])[0] for key in self.params})\n",
    "        return param_list\n",
    "        \n",
    "    def __resample_eval(self, model, X, y, verbose=False):\n",
    "        '''\n",
    "        Evaluates the model on a given set\n",
    "        \n",
    "        param model:   model to evaluate\n",
    "        param X:       Training data\n",
    "        param y:       Labels\n",
    "        param verbose: True to generate tqdm bar\n",
    "        '''\n",
    "        np.random.seed(self.random_state)\n",
    "        random_list = np.random.randint(0, 36000, size=self.num_samples)\n",
    "        if self.metric is None:\n",
    "            metric = accuracy_score  \n",
    "        sample_scores = []\n",
    "        for sample_ndx in tqdm_notebook(range(self.num_samples), disable=(not verbose)):\n",
    "            X_sample, _, y_sample, _ = train_test_split(X, y, train_size=self.sample_size, stratify=y, \n",
    "                                                        random_state=random_list[sample_ndx]+13)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=self.test_size, \n",
    "                                                                stratify=y_sample, random_state=random_list[sample_ndx])\n",
    "            clf = model.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            sample_scores.append(metric(y_test, y_pred))            \n",
    "        mean = np.mean(sample_scores)\n",
    "        std = np.std(sample_scores)\n",
    "        return mean, std\n",
    "        \n",
    "    def fit(self, X, y, verbose=False):\n",
    "        '''\n",
    "        Finds the optimal hyperparameter\n",
    "        \n",
    "        param X:       Training data\n",
    "        param y:       Labels\n",
    "        param verbose: True to generate tqdm bar\n",
    "        '''\n",
    "        for random_param in tqdm_notebook(self.param_grid, disable=(not verbose)):\n",
    "            self.model.set_params(**random_param)\n",
    "            score, std = self.__resample_eval(self.model, X, y)\n",
    "            if score>self.best_score_:\n",
    "                self.best_params_ = random_param\n",
    "                self.best_score_ = score\n",
    "                self.best_std_ = std\n",
    "                self.best_model = copy.copy(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lgbm\"></a>\n",
    "### Light Gradient Boosted Model (LGBM classifier)\n",
    "\n",
    "Not exactly related to this notebook, just want to throw it out there that LGBM is--by far--one of my favorite packages to use and the best implementation of gradient boosted tree ensembles in the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'max_depth': 16, 'loss_function': 'CrossEntropy', 'num_leaves': 118, 'learning_rate': 0.3082744216762507, 'n_estimators': 2355, 'max_bin': 6, 'boosting_type': 'dart'}\n",
      "Best resample accuracy: 79.0%\n"
     ]
    }
   ],
   "source": [
    "param_space = {'max_depth': Integer(1, 32), \n",
    "              'loss_function': Categorical(['Logloss', 'CrossEntropy']), \n",
    "              'num_leaves': Integer(2, 150),\n",
    "              'learning_rate': Real(.001, 0.5),\n",
    "              'n_estimators': Integer(100, 3000),\n",
    "              'max_bin': Integer(2, 12),\n",
    "              'boosting_type': Categorical(['gbdt', 'dart', 'goss'])}\n",
    "lgbm_seed = 7\n",
    "grid = RandomSearchResample(LGBMClassifier(random_state=lgbm_seed, n_jobs=-1), params=param_space, \n",
    "                            num_iter=120, num_samples=20, random_state=396)\n",
    "grid.fit(X_train, y_train)\n",
    "lgbm_best_params = grid.best_params_\n",
    "print(\"Best hyperparameters found: \"+str(lgbm_best_params))\n",
    "print(f\"Best resample accuracy: {pct(grid.best_score_)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of best model found: 81.63\n"
     ]
    }
   ],
   "source": [
    "lgbm_model = LGBMClassifier(**lgbm_best_params, random_state=lgbm_seed, n_jobs=-1)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "y_test_preds = lgbm_model.predict(X_test)\n",
    "print(f\"Overall accuracy of best model found: {pct(accuracy_score(y_test, y_test_preds))}\")\n",
    "save_pickle(lgbm_model, \"lgbm_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"svc1\"></a>\n",
    "### First Support Vector Classifier (SVC)\n",
    "\n",
    "This first SVC is made using a radial basis function (RBF) kernel and tuned using a simple grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'C': 10, 'gamma': 0.001}\n",
      "Best resample accuracy: 80.42%\n"
     ]
    }
   ],
   "source": [
    "param_space = {'C':[0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "svc1_seed = 42\n",
    "grid = GridSearchCV(SVC(kernel='rbf', random_state=svc1_seed), param_space, cv=3, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "svc1_best_params = grid.best_params_\n",
    "print(\"Best hyperparameters found: \"+str(svc1_best_params))\n",
    "print(f\"Best resample accuracy: {pct(grid.best_score_)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of best model found: 81.82\n"
     ]
    }
   ],
   "source": [
    "svc1_model = SVC(kernel='rbf', **svc1_best_params, probability=True, random_state=svc1_seed)\n",
    "svc1_model.fit(X_train, y_train)\n",
    "y_test_preds = svc1_model.predict(X_test)\n",
    "print(f\"Overall accuracy of best model found: {pct(accuracy_score(y_test, y_test_preds))}\")\n",
    "save_pickle(svc1_model, \"svc1_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"svc2\"></a>\n",
    "### Second Support Vector Classifier (SVC)\n",
    "\n",
    "This second SVC uses a polynomial kernel.  As we will be search over multiple polynomial degrees and training two and three degree polynomial kernels takes a long long time, the randomized search with resampling class will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'degree': 3, 'C': 0.025749617515621524, 'gamma': 0.0025749617515621525}\n",
      "Best resample accuracy: 78.44%\n"
     ]
    }
   ],
   "source": [
    "param_space = {'degree': Integer(2, 3),\n",
    "               'C': Real(0.001, 1000, prior=\"log-uniform\"),\n",
    "               'gamma': Real(0.0001, 100, prior=\"log-uniform\")}\n",
    "svc2_seed = 37\n",
    "grid = RandomSearchResample(SVC(kernel='poly', random_state=svc2_seed), params=param_space, \n",
    "                            num_iter=120, num_samples=20, random_state=19)\n",
    "grid.fit(X_train, y_train)\n",
    "svc2_best_params = grid.best_params_\n",
    "print(\"Best hyperparameters found: \"+str(svc2_best_params))\n",
    "print(f\"Best resample accuracy: {pct(grid.best_score_)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of best model found: 81.57\n"
     ]
    }
   ],
   "source": [
    "svc2_model = SVC(kernel='poly', **svc2_best_params, probability=True, random_state=svc2_seed)\n",
    "svc2_model.fit(X_train, y_train)\n",
    "y_test_preds = svc2_model.predict(X_test)\n",
    "print(f\"Overall accuracy of best model found: {pct(accuracy_score(y_test, y_test_preds))}\")\n",
    "save_pickle(svc2_model, \"svc2_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xgb\"></a>\n",
    "### XGBoost Classifier\n",
    "\n",
    "XGBoost seems to be the most popular gradient boosted tree ensemble library and for good reason.  It works.  I also considered using CatBoost as a classifier but the large number of categorical features in this data caused it to take waaaaay longer to train--even using resampling instead of crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'max_depth': 6, 'booster': 'gbtree', 'min_child_weight': 5, 'learning_rate': 0.06787839616843971, 'n_estimators': 982, 'gamma': 0.004678689346971979, 'colsample_bytree': 0.14268459360071206}\n",
      "Best resample accuracy: 78.92%\n"
     ]
    }
   ],
   "source": [
    "param_space = {'max_depth':Integer(2, 32), \n",
    "              'booster': Categorical(['gbtree', 'dart']), \n",
    "              'min_child_weight': Integer(1, 8),\n",
    "              'learning_rate': Real(0.001, 0.5),\n",
    "              'n_estimators': Integer(50, 3000),\n",
    "              'gamma': Real(0.001, 100, prior=\"log-uniform\"),\n",
    "              'colsample_bytree': Real(0.01, 1)}\n",
    "\n",
    "xgb_seed = 123\n",
    "grid = RandomSearchResample(XGBClassifier(verbosity=0, random_state=xgb_seed, n_jobs=-1), params=param_space, \n",
    "                            num_iter=120, num_samples=20, random_state=21)\n",
    "grid.fit(X_train, y_train)\n",
    "xgb_best_params = grid.best_params_\n",
    "print(\"Best hyperparameters found: \"+str(xgb_best_params))\n",
    "print(f\"Best resample accuracy: {pct(grid.best_score_)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of best model found: 81.84\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(verbosity=0, random_state=xgb_seed, n_jobs=-1, **xgb_best_params)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_test_preds = xgb_model.predict(X_test)\n",
    "print(f\"Overall accuracy of best model found: {pct(accuracy_score(y_test, y_test_preds))}\")\n",
    "save_pickle(xgb_model, \"xgb_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ensemble\"></a>\n",
    "## Training the ensemble model\n",
    "\n",
    "The class below allows me to combine the previous models together and train a new model to predict outcomes from the individual predictions.  This class is pretty large for a notebook and provides functionality to combine predictions by taking weighted averages of probabilities, taking the mode of predictions, and training an actual model to predict.  Rather than take the actual predictions of each model and combine them into an overall prediction, this class takes the *predicted probabilites* of each model and uses those probabilities to predict a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedCatEnsemble:\n",
    "    def __init__(self, model_list, ensemble_model=None, weights=None, use_probs=True):\n",
    "        '''\n",
    "        Builds an ensemble model\n",
    "        \n",
    "        param model_list:     a list of the models to be used\n",
    "        param ensemble_model: the model used to combine predictions.  If None, defaults to logistic regression\n",
    "        param weights:        Weights to define importance of each model.  Defaults to one for each model\n",
    "        param use_probs:      True to use predicted probabilities to train ensemble model.  False to use\n",
    "                              actual predictions instead.\n",
    "        '''\n",
    "        if ensemble_model is None:\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            self.ensemble_model = LogisticRegression()\n",
    "        else:\n",
    "            self.ensemble_model = ensemble_model\n",
    "        self.num_models = len(model_list)\n",
    "        self.model_list = model_list\n",
    "        self.num_labels = 1\n",
    "        self.use_probs = use_probs\n",
    "        self.optimal_params = dict()\n",
    "        self.stored_probs = None\n",
    "        self.stored_y = None\n",
    "        self.stored_test_probs = None\n",
    "        self.stored_test_y = None\n",
    "        self.stored_test = False\n",
    "        self.base_weights = np.array([1.0]*self.num_models)\n",
    "        self.max_weights = np.array([1.0]*self.num_models)\n",
    "        if weights is None:\n",
    "            self.weights = np.array([1.0]*self.num_models)\n",
    "        else:\n",
    "            self.weights = np.array(weights)\n",
    "\n",
    "    def set_data(self, X_train=None, y_train=None, X_test=None, y_test=None, weighted=False, verbose=False):\n",
    "        '''\n",
    "        Stores the main data splits used.  Done to save time on by only calculating predicted probabilities for both\n",
    "        once instead of every time.\n",
    "        \n",
    "        param X_train:   Training data\n",
    "        param y_train:   Training labels\n",
    "        param X_test:    Testing data\n",
    "        param y_test:    Testing labels\n",
    "        param weighted:  If True, use weighting scheme\n",
    "        '''\n",
    "        if X_train is not None:\n",
    "            self.stored_probs = self.__prob_array(X_train, weighted=weighted, verbose=verbose)\n",
    "        if X_test is not None:\n",
    "            self.stored_test = True\n",
    "            self.stored_test_probs = self.__prob_array(X_test, weighted=weighted, verbose=verbose)\n",
    "        if y_test is not None:\n",
    "            self.stored_test_y = y_test\n",
    "        if y_train is not None:\n",
    "            self.stored_y = y_train\n",
    "    \n",
    "    def set_weights(self, weights=\"base\"):\n",
    "        '''\n",
    "        Change importance weights\n",
    "        \n",
    "        param weights:  \"base\" to equally weight each model.  \"max\" to use generated maximal weigts.  Any other set\n",
    "                         input will be used as the weights directly.\n",
    "        '''\n",
    "        if weights==\"base\":\n",
    "            self.weights = self.base_weights\n",
    "        elif weights==\"max\":\n",
    "            self.weights = self.max_weights\n",
    "        else:\n",
    "            self.weights = weights\n",
    "\n",
    "    def change_ensemble_method(self, ensemble_model, weighted=False):\n",
    "        '''\n",
    "        Change the model used to predict outcomes from other models\n",
    "        \n",
    "        param ensemble_model:  New ensemble method to use\n",
    "        weighted:              If True, use weights to specify importance\n",
    "        \n",
    "        Returns: Predictions of model on training data\n",
    "        '''\n",
    "        self.ensemble_model = ensemble_model\n",
    "        if weighted:\n",
    "            X = self.stored_probs*self.weights\n",
    "        else:\n",
    "            X = self.stored_probs\n",
    "        self.ensemble_model.fit(X, self.stored_y)\n",
    "        return self.ensemble_model.predict(X)\n",
    "    \n",
    "    def tune_hyperparameters(self, hyperparameters, num_samples=5, method=\"bayes\", n_iter=60, \n",
    "                             n_jobs=-1, sample_size=0.2, test_size=0.3, verbose=0, random_state=None, train_final=True, \n",
    "                             return_accuracy=False, return_search=False, weighted=False):\n",
    "        '''\n",
    "        Automatically tunes hyperparameters for ensemble model\n",
    "        \n",
    "        param hyperparameters:     Hyperparameter grid to use\n",
    "        param num_samples:         Number of samples or crossvalidation folds to use\n",
    "        param method:              \"bayes\" for Bayesian optimization.  \"grid\" for cv grid search. \"random\" for \n",
    "                                    cv randomized search.  \"random-resample\" for resampled randomized search\n",
    "        param n_iter:              Number of iterations to use for Bayes or randomized methods\n",
    "        param n_jobs:              Number of cores to use\n",
    "        param sample_size:         Sample size for resample methods\n",
    "        param test_size:           Test set size in resamples\n",
    "        param verbose:             Verbosity of search.  Higher integers return more status.  Does not work with random-resample\n",
    "        param train_final:         If true, train ensemble model on optimal hyperparameters\n",
    "        param return_accuracy:     Return accuracy with parameters if True\n",
    "        param return_search:       If true, return the actual search model.  Can be used with random-resample to plot\n",
    "                                   distribution of sample accuracy if using full class found in GitHub link further up\n",
    "        param weighted:            If True, uses weighted predicted probabilities\n",
    "        \n",
    "        Returns:                   Some combination of best params, best score, and the search function itself\n",
    "        '''\n",
    "        if method==\"bayes\":\n",
    "            grid = BayesSearchCV(self.ensemble_model, hyperparameters, cv=num_samples, n_iter=n_iter, \n",
    "                                 verbose=verbose, n_jobs=n_jobs, random_state=random_state)\n",
    "        elif method==\"grid\":\n",
    "            grid = GridSearchCV(self.ensemble_model, hyperparameters, cv=num_samples, \n",
    "                                verbose=verbose, n_jobs=n_jobs)\n",
    "        elif method==\"random\":\n",
    "            grid = RandomizedSearchCV(self.ensemble_model, hyperparameters, cv=num_samples, n_iter=n_iter, \n",
    "                                      verbose=verbose, n_jobs=n_jobs, random_state=random_state)\n",
    "        elif method==\"random-resample\":\n",
    "            grid = RandomSearchResample(self.ensemble_model, params=hyperparameters, num_iter=n_iter, sample_size=sample_size,\n",
    "                                        num_samples=num_samples, test_size=test_size, random_state=random_state)\n",
    "        X = self.__prob_array(X=\"train\", weighted=weighted)\n",
    "        grid.fit(X, self.stored_y)\n",
    "        if train_final:\n",
    "            model = self.ensemble_model.set_params(**grid.best_params_)\n",
    "            model.fit(X, self.stored_y)\n",
    "        self.optimal_params = grid.best_params_\n",
    "        self.ensemble_model.set_params(**self.optimal_params)\n",
    "        if return_accuracy:\n",
    "            if return_search:\n",
    "                return grid.best_params_, grid.best_score_, grid\n",
    "            else:\n",
    "                return grid.best_params_, grid.best_score_\n",
    "        else:\n",
    "            if return_search:\n",
    "                 return grid.best_params_, grid\n",
    "            else:\n",
    "                return grid.best_params_\n",
    "\n",
    "    def maximize_weights(self, weight_grid=None, method=\"random\", set_weights=True, n_iter=1500, \n",
    "                         return_acc=True, random_state=None, verbose=False):\n",
    "        '''\n",
    "        Find weights which maximize accuracy of training data\n",
    "        \n",
    "        param weight_grid:   List of list of weights to search combinations of\n",
    "        param set_weights:   Set maximal weights found for future use\n",
    "        param n_iter:        Number of weight combinations to try\n",
    "        param method:        \"random\" to check random weights.  Anything else and a grid search is performed\n",
    "        param return_acc:    Return the best accuracy found\n",
    "        \n",
    "        Returns:  Maximal weighting found and maximum accuracy found (if return_acc=True)\n",
    "        '''\n",
    "        max_acc = 0.0\n",
    "        max_acc_weights = []\n",
    "        X = self.__prob_array(X=\"train\")\n",
    "        y = self.stored_y\n",
    "        if weight_grid is None:\n",
    "            simple_grid = np.arange(start=0.0, stop=1.01, step=0.05)\n",
    "            weight_grid = [simple_grid for _ in range(self.num_models)]\n",
    "        weight_grid = itertools.product(*weight_grid)\n",
    "        if method==\"random\":\n",
    "            random.seed(random_state)\n",
    "            weight_grid = random.sample(list(weight_grid), n_iter)\n",
    "        for weights in tqdm_notebook(weight_grid, disable=(not verbose)):\n",
    "            acc = accuracy_score(y, self.mean(X=X, weights=list(weights), need_prob_array=False))\n",
    "            if acc>max_acc:\n",
    "                max_acc = acc\n",
    "                max_acc_weights = weights\n",
    "        self.max_weights = weights\n",
    "        if set_weights:\n",
    "            self.weights = max_acc_weights\n",
    "        if return_acc:\n",
    "            return self.max_weights, max_acc\n",
    "        else:\n",
    "            return self.max_weights\n",
    "\n",
    "    def mean(self, X=\"train\", weights=\"base\", need_prob_array=True, probs=False, verbose=False):\n",
    "        '''\n",
    "        Calculates mean of a data set\n",
    "        \n",
    "        X:                Probability set to find mean of.  If \"train\", uses training data.  If \"test\", uses test data.\n",
    "        weights:          Weights to use\n",
    "        need_prob_array:  If True, generate probability array.  If False, use raw X input\n",
    "        probs:            If true, return predicted probabilities.  If False, return predictions\n",
    "        \n",
    "        Returns:  Predicted probabilities or predictions\n",
    "        '''\n",
    "        self.set_weights(weights)\n",
    "        if need_prob_array: og_probs = self.__prob_array(X, weighted=True, verbose=verbose)\n",
    "        else: og_probs = X*self.weights\n",
    "        total_weight = np.sum(self.weights)\n",
    "        if total_weight==0:\n",
    "            return np.array([0.0]*len(og_probs))\n",
    "        weighted_probs = []\n",
    "        for row in og_probs:\n",
    "            val = np.sum(row)/total_weight\n",
    "            if not probs:\n",
    "                val = int(round(val))\n",
    "            weighted_probs.append(val)\n",
    "        return np.array(weighted_probs)\n",
    "    \n",
    "    def fit(self, X, y, weighted=False, verbose=False, return_predictions=False):\n",
    "        '''\n",
    "        Fits ensemble model\n",
    "        \n",
    "        X:         Training data\n",
    "        y:         Labels\n",
    "        weighted:  If True, use weights\n",
    "        \n",
    "        Returns:  Predictions for X if return_predictions=True.  Else, return nothing.\n",
    "        '''\n",
    "        self.num_labels = len(y.unique())-1\n",
    "        X_probs = self.__prob_array(X, weighted=weighted, verbose=verbose)\n",
    "        self.stored_probs = X_probs\n",
    "        self.stored_y = y\n",
    "        self.ensemble_model.fit(X_probs, y)\n",
    "        if return_predictions:\n",
    "            return self.ensemble_model.predict(X_probs)\n",
    "        \n",
    "    def predict(self, X, verbose=False, weighted=False):\n",
    "        '''\n",
    "        Predict labels from a set X\n",
    "        '''\n",
    "        X_probs = self.__prob_array(X, verbose=verbose, weighted=weighted)\n",
    "        return self.ensemble_model.predict(X_probs)\n",
    "        \n",
    "    def predict_proba(self, X, weighted=False):\n",
    "        '''\n",
    "        Predict probabilities from a set X\n",
    "        '''\n",
    "        X_probs = self.__prob_array(X, weighted=weighted)\n",
    "        return self.ensemble_model.predict_proba(X_probs)\n",
    "    \n",
    "    def mode_predict(self, X=\"train\"):\n",
    "        '''\n",
    "        Predicts labels of a set by taking the mode of predictions\n",
    "        '''\n",
    "        X = self.__prob_array(X)\n",
    "        X = X.round().astype(int)\n",
    "        pred = stats.mode(X, axis=1)[0]\n",
    "        return pred\n",
    "        \n",
    "    def __prob_array(self, X, weighted=False, verbose=False):\n",
    "        '''\n",
    "        Takes a data set and returns an array of probabilities\n",
    "        \n",
    "        X:         Data\n",
    "        weighted:  True to use weights\n",
    "        '''\n",
    "        if weighted:\n",
    "            weights = self.weights\n",
    "        else:\n",
    "            weights=1.0\n",
    "        if X==\"train\":\n",
    "            return self.stored_probs*weights\n",
    "        elif X==\"test\":\n",
    "            return self.stored_test_probs*weights\n",
    "        num_rows = len(self.__get_features(X, 0))\n",
    "        prob_matrix = np.zeros((num_rows, self.num_models*self.num_labels), dtype='float32')\n",
    "        for index in tqdm_notebook(range(self.num_models), disable=(not verbose)):\n",
    "            if self.num_labels>1:\n",
    "                prob_matrix[:, index:index+self.num_labels] = self.__predict(self.model_list[index], \n",
    "                                                                             self.__get_features(X, index))\n",
    "            else:\n",
    "                prob_matrix[:, index] = self.__predict(self.model_list[index], self.__get_features(X, index))\n",
    "        return prob_matrix*weights\n",
    "        \n",
    "    def __predict(self, model, X):\n",
    "        '''\n",
    "        Returns probability predictions of X by a model.\n",
    "        \n",
    "        If model doesn't allow predicted probabilities, return predictions\n",
    "        '''\n",
    "        if not self.use_probs:\n",
    "            return model.predict(X)\n",
    "        try:\n",
    "            multi_channel = model.predict_proba(X)\n",
    "            if self.num_labels==1:\n",
    "                return np.reshape(multi_channel[:,1:], len(X))\n",
    "            else:\n",
    "                return multi_channel[:,1:]\n",
    "        except:\n",
    "            return model.predict(X)\n",
    "        \n",
    "    def __get_features(self, X, index=None):\n",
    "        '''\n",
    "        If a singleton is input, create a copied list of it\n",
    "        '''\n",
    "        if type(X)==list:\n",
    "            return X[index]\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eyeswide](https://media.giphy.com/media/xThta7HUIMJp2SRAdi/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mean\"></a>\n",
    "### Simple mean of probabilities\n",
    "\n",
    "This first ensemble method takes a simple average of each model's predicted probabilities and predicts an outcome for a great 82.6% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple model mean has 82.26% accuracy on validation data and 82.6% on test data.\n"
     ]
    }
   ],
   "source": [
    "model_list = [log_model, lgbm_model, svc1_model, svc2_model, xgb_model]\n",
    "X_val_list = [X_val_ord] + [X_val]*4\n",
    "X_test_list = [X_test_ord] + [X_test]*4\n",
    "ensemble = PretrainedCatEnsemble(model_list, LogisticRegressionCV(np.logspace(-5, 5), random_state=5))\n",
    "ensemble.set_data(X_val_list, y_val, X_test_list, y_test)\n",
    "\n",
    "val_preds = ensemble.mean(X=\"train\", weights=\"base\")\n",
    "test_preds = ensemble.mean(X=\"test\", weights=\"base\")\n",
    "val_acc = pct(accuracy_score(y_val, val_preds))\n",
    "test_acc = pct(accuracy_score(y_test, test_preds))\n",
    "print(f\"A simple model mean has {val_acc}% accuracy on validation data and {test_acc}% on test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"weighted_mean\"></a>\n",
    "### Weighted mean of probabilities\n",
    "\n",
    "This next method uses a random search to look for a set of weights which maximizes predicted accuracy on the validation set.  True to form, this method provided better accuracy on the test set than the simple mean HOWEVER it did worse on the test set.\n",
    "\n",
    "Interestingly, the weights found prioritize the two SVCs and the logistic regression model heavily over the two ensemble tree models.  This indicates that it may be worth looking into a simple ensemble that just consists of those three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A validation set (approximate) maximally weighted mean has 82.47% accuracy on validation data and 82.25% on test data.\n",
      "The approximate maximal mean weights are log_model, lgbm_model, svc1_model, svc2_model, xgb_model, cb_model = (0.55, 0.1, 0.9500000000000001, 0.6000000000000001, 0.05)\n"
     ]
    }
   ],
   "source": [
    "weights, val_acc = ensemble.maximize_weights(random_state=15, n_iter=2500)\n",
    "test_acc = pct(accuracy_score(y_test, ensemble.mean(X=\"test\", weights=\"max\")))\n",
    "print(f\"A validation set (approximate) maximally weighted mean has {pct(val_acc)}% \"+\n",
    "      f\"accuracy on validation data and {test_acc}% on test data.\")\n",
    "print(f\"The approximate maximal mean weights are log_model, lgbm_model, svc1_model, \"+\n",
    "      f\"svc2_model, xgb_model, cb_model = {weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mode\"></a>\n",
    "### Mode of predictions\n",
    "\n",
    "This section just takes the mode of the prediction from all models and manages to pull 82.37% on the test set--showing that sometimes the simplest methods perform well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the simple mode of model predictions gives 82.26% accuracy on validation data and 82.37% on test data.\n"
     ]
    }
   ],
   "source": [
    "val_preds = ensemble.mode_predict(X=\"train\")\n",
    "test_preds = ensemble.mode_predict(X=\"test\")\n",
    "val_acc = pct(accuracy_score(y_val, val_preds))\n",
    "test_acc = pct(accuracy_score(y_test, test_preds))\n",
    "print(f\"Taking the simple mode of model predictions gives {val_acc}% accuracy on validation data and {test_acc}% on test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"logensemble\"></a>\n",
    "### Ensemble with logistic regression\n",
    "\n",
    "The next section uses LogisticRegressionCV to give a quick, tuned label predicted from the individual models.  As with the unweighted mean, this does better on the test set than the training set and pulls a solid 82.58%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression ensemble model gives 82.4% accuracy on validation data and 82.58% on test data.\n"
     ]
    }
   ],
   "source": [
    "val_preds = ensemble.fit(X_val_list, y_val, return_predictions=True)\n",
    "test_preds = ensemble.predict(X=\"test\")\n",
    "val_acc = pct(accuracy_score(y_val, val_preds))\n",
    "test_acc = pct(accuracy_score(y_test, test_preds))\n",
    "print(f\"Logistic Regression ensemble model gives {val_acc}% accuracy on validation data and {test_acc}% on test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"svcensemble\"></a>\n",
    "### Ensemble with SVC\n",
    "\n",
    "This next ensemble is built using an SVC with RBF kernel and it is the best performer of all ensembles with 81.88% on the validation data and 81.81% on the test data.  Interestingly, this accuracy comes from the *untuned* model--which performs better than the model tuned with grid search crossvalidation.  Why this is, I'm not sure--but I suspect it has to do with the 'auto' procedure scikit-learn's SVC algorithm uses to select gamma values.  Including 'auto' in the parameter list along with other gamma values will be standard operating procedure for me next time I tune an SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ensembled by untuned SVC with RBF kernel gives 81.88% accuracy on validation data and 81.81% on test data.\n"
     ]
    }
   ],
   "source": [
    "val_preds = ensemble.change_ensemble_method(SVC(kernel=\"rbf\", random_state=4))\n",
    "test_preds = ensemble.predict(X=\"test\")\n",
    "val_acc = pct(accuracy_score(y_val, val_preds))\n",
    "test_acc = pct(accuracy_score(y_test, test_preds))\n",
    "print(f\"Model ensembled by untuned SVC with RBF kernel gives {val_acc}% accuracy \"+\n",
    "      f\"on validation data and {test_acc}% on test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters {'C': 1, 'gamma': 10} give a K-fold crossvalidation score of 82.27% on the validation data.\n"
     ]
    }
   ],
   "source": [
    "param_space = {'C': [.001, .01, 1, 10, 100],\n",
    "              'gamma': [.0001, .001, .01, .1, 1, 10]}\n",
    "\n",
    "best_params, score = ensemble.tune_hyperparameters(param_space, method='grid', num_samples=5, n_jobs=-1, return_accuracy=True)\n",
    "print(f\"The hyperparameters {best_params} give a K-fold crossvalidation score of {pct(score)}% on the validation data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ensembled by tuned SVC with RBF kernel gives 82.78% accuracy on validation data and 82.49% on test data.\n"
     ]
    }
   ],
   "source": [
    "val_preds = ensemble.predict(X=\"train\")\n",
    "test_preds = ensemble.predict(X=\"test\")\n",
    "val_acc = pct(accuracy_score(y_val, val_preds))\n",
    "test_acc = pct(accuracy_score(y_test, test_preds))\n",
    "print(f\"Model ensembled by tuned SVC with RBF kernel gives {val_acc}% accuracy \"+\n",
    "      f\"on validation data and {test_acc}% on test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"treeensemble\"></a>\n",
    "### Ensemble with decision tree\n",
    "\n",
    "The final ensemble model tested will be a simple decision tree classifier.  A big thing to note here is that the model performed **horribly** untuned but did much better after being tuned.  It was still the worst of all methods even when it was tuned but it at least got into the ballpark of the other ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ensembled by untuned decision tree gives 100.0% accuracy on validation data and 74.35% on test data.\n"
     ]
    }
   ],
   "source": [
    "val_preds = ensemble.change_ensemble_method(DecisionTreeClassifier(random_state=4))\n",
    "test_preds = ensemble.predict(X=\"test\")\n",
    "val_acc = pct(accuracy_score(y_val, val_preds))\n",
    "test_acc = pct(accuracy_score(y_test, test_preds))\n",
    "print(f\"Model ensembled by untuned decision tree gives {val_acc}% accuracy on validation data and {test_acc}% on test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters {'criterion': 'gini', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_split': 0.01405703022052757, 'min_samples_leaf': 0.012008025058644959, 'splitter': 'random'} give a resample score of 81.9% on the validation data.\n"
     ]
    }
   ],
   "source": [
    "param_space = {'criterion': Categorical(['gini', 'entropy']), \n",
    "              'max_depth':Integer(2, 32),\n",
    "               'max_features': Categorical(['sqrt', 'log2', None]),\n",
    "              'min_samples_split': Real(0.01, 1.00),\n",
    "               'min_samples_leaf': Real(0.01, 0.5),\n",
    "              'splitter': Categorical(['random', 'best'])}\n",
    "\n",
    "ensemble.change_ensemble_method(DecisionTreeClassifier(random_state=4))\n",
    "best_params, score = ensemble.tune_hyperparameters(param_space, method='random-resample', \n",
    "                                                   n_iter=500, sample_size=0.5, num_samples=10, return_accuracy=True)\n",
    "print(f\"The hyperparameters {best_params} give a resample score of {pct(score)}% on the validation data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ensembled by tuned decision tree gives 81.72% accuracy on validation data and 82.28% on test data.\n"
     ]
    }
   ],
   "source": [
    "val_preds = ensemble.predict(X=\"train\")\n",
    "test_preds = ensemble.predict(X=\"test\")\n",
    "val_acc = pct(accuracy_score(y_val, val_preds))\n",
    "test_acc = pct(accuracy_score(y_test, test_preds))\n",
    "print(f\"Model ensembled by tuned decision tree gives {val_acc}% accuracy on validation data and {test_acc}% on test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusions\"></a>\n",
    "## Conclusions\n",
    "\n",
    "To reiterate what I said at first, I was fighting soooo hard with this data to get any increase in accuracy.  In a future notebook applying deep learning techniques to this problem, you'll see that this is true in that domain as well.  Most likely, 83% is reaching the maximum predictive information that answers to these personality questions can give us about a person's gender.\n",
    "\n",
    "As for picking a final model, there are really three main winners I can see that each have their own advantages.  The clear ensemble method for accuracy is using SVC with an RBF kernel.  This model gave us better accuracy on the validation and test sets than any other method.  Logistic regression didn't score as high on accuracy, but the value of the calibrated probabilities that logistic regression gives cannot be overstated.  Lastly, the simple probability mean performed very well on the test set and is--by far--the fastest of the three methods.  It's overperformance on the test set compared to the validation set tells me that part of it's performance may be due to luck of the draw when splitting the data and not something inherent to the method itself, though.\n",
    "\n",
    "Honestly, depending on how necessary the extra 3% predictive accuracy it, it may be better to just skip the entire ensemble procedure and just use a single and simple tuned logistic regression model to predict gender.  It's quick, easy, and gives *good enough* predictions on it's own without being stacked.  Also, I really love logistic regression.  Have I said that before?  Because I really. love. logistic. regression.\n",
    "\n",
    "![thumbsup](https://media.giphy.com/media/S1Ap7GTcjToZy/giphy.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
